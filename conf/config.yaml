defaults:
  - model: mlp
  - datamodule: fashion_mnist
  - loop: default_loop
  - logger: wandb_min_max
  - callbacks:
      - model_checkpoint
      - early_stopping

  - _self_

random_seed: 1590258941
num_workers: 4
log_gradients: False

trainer:
  gpus: 1
  max_epochs: 100
  accumulate_grad_batches: 1
  precision: 32

# accessed by base datamodule, here for convenience
train_batch_size: 32
test_batch_size: ${train_batch_size}

metrics:
  # apply before passing to metrics
  to_probabilities: 'softmax'
  metrics_list:
    - _target_: torchmetrics.Accuracy
    - _target_: torchmetrics.F1Score
      num_classes: 10

hydra:
  run:
    dir: ./outputs/single/${model._target_}/${now:%Y-%m-%d}/${now:%H-%M-%S}

  sweep:
    dir: outputs/sweep/${now:%Y-%m-%d}/${now:%H-%M-%S}
    # subdir: lr:${loop.optimizer.lr}